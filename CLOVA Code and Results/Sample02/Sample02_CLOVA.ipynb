{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLOVA_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB6E6RYnyl4d",
        "outputId": "e640f884-a02a-4e99-fc45-9cc91862084e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4tmBZmTyn2q",
        "outputId": "7330c772-5a8f-4e74-9f72-8d36e06db1d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd \"/content/drive/My Drive/CZ4003\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CZ4003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxSgyNoOBl-X"
      },
      "source": [
        "## OCR detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z39CCsT7zhu"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbz4XJbpIFOs"
      },
      "source": [
        "if not os.path.exists('./cropped_images'):\n",
        "  os.mkdir('./cropped_images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0PuftFbAX9u"
      },
      "source": [
        "# Get files\n",
        "def get_files(folder_name, file_types):\n",
        "  detected_files = []\n",
        "  for file_type in file_types:\n",
        "    print(file_type)\n",
        "    for file in glob.glob(folder_name + f\"/*.{file_type}\"):\n",
        "        detected_files.append(file)\n",
        "  \n",
        "  return sorted(detected_files)\n",
        "\n",
        "def tilted_box_transform(coor):\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(coor)):\n",
        "        if i % 2 == 0:\n",
        "            x.append(coor[i])\n",
        "        else:\n",
        "            y.append(coor[i])\n",
        "    try:\n",
        "        max_x = max(x)\n",
        "        min_x = min(x)\n",
        "        max_y = max(y)\n",
        "        min_y = min(y)\n",
        "        new_coor = [min_x, min_y, max_x, min_y, max_x, max_y, min_x, max_y]\n",
        "    except ValueError:\n",
        "        return []\n",
        "\n",
        "    return new_coor\n",
        "\n",
        "# Extract coordinates of detected bounding boxes from *.txt files\n",
        "def get_coordinates(file):\n",
        "    coordinates = []\n",
        "    rect = []\n",
        "    file = file.replace(\" \", \"\")\n",
        "    file = list(file.strip().split(\"\\n\"))\n",
        "    if len(file[0]) != 0: \n",
        "        for text in file:\n",
        "            coor = [int(s) for s in text.split(\",\")[:8]] #if s[0].isdigit()]\n",
        "            if text:\n",
        "                coordinates.append(coor)\n",
        "    for i in range(len(coordinates)):\n",
        "        #print(coordinates[i])\n",
        "        coordinates[i] = tilted_box_transform(coordinates[i])\n",
        "    \n",
        "        rect_coor = (coordinates[i][0], coordinates[i][1], coordinates[i][2]-coordinates[i][0], coordinates[i][7]-coordinates[i][1])\n",
        "        rect.append(rect_coor)\n",
        "\n",
        "    return rect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXBY5Nlq7D9k",
        "outputId": "b085e334-e86a-42e3-839b-2218a78e31b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python ./CRAFT-pytorch-master/test.py --trained_model=./CRAFT-pytorch-master/craft_mlt_25k.pth --test_folder=./sample_images --cuda False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights from checkpoint (./CRAFT-pytorch-master/craft_mlt_25k.pth)\n",
            "Test image 1/1: ./sample_images/sample02.png\relapsed time : 14.151941537857056s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBt8347-Fhkp"
      },
      "source": [
        "meme_path = \"memes/sample02.png\"\n",
        "meme = cv2.imread(meme_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLxRiTG_JXuC",
        "outputId": "d466a452-a3f9-469a-881b-1199960c8ea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "meme_files = get_files('result', ['txt'])\n",
        "meme_images = get_files('sample_images', ['png','jpg','jpeg'])\n",
        "print(meme_files)\n",
        "print(meme_images)\n",
        "for meme_id in range(len(meme_files)):\n",
        "  meme = cv2.imread(meme_images[meme_id])\n",
        "  with open(meme_files[meme_id], 'r') as f: \n",
        "    gt = f.read()\n",
        "  gt_coor = get_coordinates(gt)\n",
        "\n",
        "  line = 0\n",
        "  gt_coor_new = []\n",
        "  for i in range(len(gt_coor)):\n",
        "    if i != 0:\n",
        "      if abs(gt_coor[i][1]- gt_coor[i-1][1]) > 10:\n",
        "        line += 1 \n",
        "    gt_coor_new.append([line, gt_coor[i]]) \n",
        "\n",
        "  bboxes = [] # [line, (bottom_left_x, bottom_left_y, x_width, y_height)]\n",
        "  for object_id in range(len(gt_coor_new)):\n",
        "    bboxes.append(gt_coor_new[object_id])\n",
        "  bboxes = sorted(bboxes , key=lambda k: [k[0], k[1][0], k[1][1]])\n",
        "\n",
        "  for text_id in range(len(bboxes)):\n",
        "    p1 = (int(bboxes[text_id][1][0]), int(bboxes[text_id][1][1]))\n",
        "    p2 = (int(bboxes[text_id][1][0] + bboxes[text_id][1][2]), int(bboxes[text_id][1][1] + bboxes[text_id][1][3]))\n",
        "    img_crop = meme[p1[1]:p2[1],p1[0]:p2[0]]\n",
        "    save_path = f'cropped_images/crop_meme_{meme_id}_pt_{text_id}.jpg'\n",
        "    cv2.imwrite(save_path, img_crop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "txt\n",
            "png\n",
            "jpg\n",
            "jpeg\n",
            "['result/res_sample02.txt']\n",
            "['sample_images/sample02.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCnSNsfs8Xsb",
        "outputId": "5eccfce7-df01-4ba0-c147-07f6c54c8212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python ./deep-text-recognition-benchmark-master/demo.py --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn --image_folder cropped_images --saved_model ./deep-text-recognition-benchmark-master/TPS-ResNet-BiLSTM-Attn-case-sensitive.pth --sensitive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model input parameters 32 100 20 1 512 256 96 25 TPS ResNet BiLSTM Attn\n",
            "loading pretrained model from ./deep-text-recognition-benchmark-master/TPS-ResNet-BiLSTM-Attn-case-sensitive.pth\n",
            "--------------------------------------------------------------------------------\n",
            "image_path               \tpredicted_labels         \tconfidence score\n",
            "--------------------------------------------------------------------------------\n",
            "cropped_images/crop_meme_0_pt_0.jpg\tSonnet                   \t0.9999\n",
            "cropped_images/crop_meme_0_pt_1.jpg\tfor                      \t1.0000\n",
            "cropped_images/crop_meme_0_pt_2.jpg\tLena                     \t0.9996\n",
            "cropped_images/crop_meme_0_pt_3.jpg\t0                        \t0.4729\n",
            "cropped_images/crop_meme_0_pt_4.jpg\tdear                     \t0.9893\n",
            "cropped_images/crop_meme_0_pt_5.jpg\tLenu,                    \t0.4478\n",
            "cropped_images/crop_meme_0_pt_6.jpg\tyour                     \t0.9991\n",
            "cropped_images/crop_meme_0_pt_7.jpg\tbeauly                   \t0.8301\n",
            "cropped_images/crop_meme_0_pt_8.jpg\tis                       \t0.9757\n",
            "cropped_images/crop_meme_0_pt_9.jpg\tso                       \t0.6472\n",
            "cropped_images/crop_meme_0_pt_10.jpg\tvast                     \t0.4334\n",
            "cropped_images/crop_meme_0_pt_11.jpg\tIt                       \t0.7362\n",
            "cropped_images/crop_meme_0_pt_12.jpg\tis                       \t0.9962\n",
            "cropped_images/crop_meme_0_pt_13.jpg\thard                     \t0.9987\n",
            "cropped_images/crop_meme_0_pt_14.jpg\tsomet                    \t0.6251\n",
            "cropped_images/crop_meme_0_pt_15.jpg\tlines                    \t0.4757\n",
            "cropped_images/crop_meme_0_pt_16.jpg\tto                       \t0.9994\n",
            "cropped_images/crop_meme_0_pt_17.jpg\tdescribe                 \t0.9932\n",
            "cropped_images/crop_meme_0_pt_18.jpg\tit                       \t0.9645\n",
            "cropped_images/crop_meme_0_pt_19.jpg\tfast,                    \t0.4962\n",
            "cropped_images/crop_meme_0_pt_20.jpg\tI                        \t0.9926\n",
            "cropped_images/crop_meme_0_pt_21.jpg\tthought                  \t0.9998\n",
            "cropped_images/crop_meme_0_pt_22.jpg\tthe                      \t0.9998\n",
            "cropped_images/crop_meme_0_pt_23.jpg\tentire                   \t0.9961\n",
            "cropped_images/crop_meme_0_pt_24.jpg\tworld                    \t0.9996\n",
            "cropped_images/crop_meme_0_pt_25.jpg\tI                        \t0.9963\n",
            "cropped_images/crop_meme_0_pt_26.jpg\twould                    \t0.9999\n",
            "cropped_images/crop_meme_0_pt_27.jpg\timpress                  \t0.9817\n",
            "cropped_images/crop_meme_0_pt_28.jpg\tthe                      \t0.3087\n",
            "cropped_images/crop_meme_0_pt_29.jpg\tonly                     \t0.9996\n",
            "cropped_images/crop_meme_0_pt_30.jpg\tyour                     \t0.9998\n",
            "cropped_images/crop_meme_0_pt_31.jpg\tportrait                 \t0.9956\n",
            "cropped_images/crop_meme_0_pt_32.jpg\tI                        \t0.9777\n",
            "cropped_images/crop_meme_0_pt_33.jpg\tcould                    \t0.9921\n",
            "cropped_images/crop_meme_0_pt_34.jpg\tcompross.                \t0.2292\n",
            "cropped_images/crop_meme_0_pt_35.jpg\tAlas!                    \t0.3195\n",
            "cropped_images/crop_meme_0_pt_36.jpg\tFirst                    \t0.9974\n",
            "cropped_images/crop_meme_0_pt_37.jpg\twhen                     \t0.9998\n",
            "cropped_images/crop_meme_0_pt_38.jpg\tI                        \t0.9925\n",
            "cropped_images/crop_meme_0_pt_39.jpg\ttried                    \t0.9977\n",
            "cropped_images/crop_meme_0_pt_40.jpg\tto                       \t0.9795\n",
            "cropped_images/crop_meme_0_pt_41.jpg\tuse                      \t0.7791\n",
            "cropped_images/crop_meme_0_pt_42.jpg\tVq                       \t0.3423\n",
            "cropped_images/crop_meme_0_pt_43.jpg\tI                        \t0.9170\n",
            "cropped_images/crop_meme_0_pt_44.jpg\tfound                    \t0.9936\n",
            "cropped_images/crop_meme_0_pt_45.jpg\tthat                     \t0.9997\n",
            "cropped_images/crop_meme_0_pt_46.jpg\tyour                     \t0.9989\n",
            "cropped_images/crop_meme_0_pt_47.jpg\tchecks                   \t0.6898\n",
            "cropped_images/crop_meme_0_pt_48.jpg\tbelong                   \t0.9965\n",
            "cropped_images/crop_meme_0_pt_49.jpg\tto                       \t0.9996\n",
            "cropped_images/crop_meme_0_pt_50.jpg\tonly                     \t0.9996\n",
            "cropped_images/crop_meme_0_pt_51.jpg\tyou.                     \t0.9780\n",
            "cropped_images/crop_meme_0_pt_52.jpg\tYour                     \t0.9992\n",
            "cropped_images/crop_meme_0_pt_53.jpg\tsilky                    \t0.9987\n",
            "cropped_images/crop_meme_0_pt_54.jpg\thair                     \t0.9019\n",
            "cropped_images/crop_meme_0_pt_55.jpg\tcontains                 \t0.9762\n",
            "cropped_images/crop_meme_0_pt_56.jpg\ta                        \t0.4361\n",
            "cropped_images/crop_meme_0_pt_57.jpg\tthousand                 \t0.9930\n",
            "cropped_images/crop_meme_0_pt_58.jpg\tlines                    \t0.9201\n",
            "cropped_images/crop_meme_0_pt_59.jpg\tHard                     \t0.9988\n",
            "cropped_images/crop_meme_0_pt_60.jpg\tto                       \t0.9947\n",
            "cropped_images/crop_meme_0_pt_61.jpg\tmatch                    \t0.9452\n",
            "cropped_images/crop_meme_0_pt_62.jpg\twith                     \t0.9999\n",
            "cropped_images/crop_meme_0_pt_63.jpg\tsums                     \t0.9715\n",
            "cropped_images/crop_meme_0_pt_64.jpg\tof                       \t0.9998\n",
            "cropped_images/crop_meme_0_pt_65.jpg\tdiscrete                 \t0.9062\n",
            "cropped_images/crop_meme_0_pt_66.jpg\tcosines.                 \t0.9130\n",
            "cropped_images/crop_meme_0_pt_67.jpg\tAnd                      \t0.9999\n",
            "cropped_images/crop_meme_0_pt_68.jpg\tfor                      \t0.9998\n",
            "cropped_images/crop_meme_0_pt_69.jpg\tyour                     \t0.9976\n",
            "cropped_images/crop_meme_0_pt_70.jpg\tlips,                    \t0.9988\n",
            "cropped_images/crop_meme_0_pt_71.jpg\tsensual                  \t0.9949\n",
            "cropped_images/crop_meme_0_pt_72.jpg\tand                      \t0.9954\n",
            "cropped_images/crop_meme_0_pt_73.jpg\ttactual                  \t0.6317\n",
            "cropped_images/crop_meme_0_pt_74.jpg\tThirteen                 \t0.8181\n",
            "cropped_images/crop_meme_0_pt_75.jpg\tCrays                    \t0.9992\n",
            "cropped_images/crop_meme_0_pt_76.jpg\tfound                    \t0.9974\n",
            "cropped_images/crop_meme_0_pt_77.jpg\tnot                      \t0.9700\n",
            "cropped_images/crop_meme_0_pt_78.jpg\tthe                      \t0.9998\n",
            "cropped_images/crop_meme_0_pt_79.jpg\tproper                   \t0.9996\n",
            "cropped_images/crop_meme_0_pt_80.jpg\tfractal.                 \t0.9442\n",
            "cropped_images/crop_meme_0_pt_81.jpg\tAnd                      \t0.9999\n",
            "cropped_images/crop_meme_0_pt_82.jpg\twhile                    \t0.9947\n",
            "cropped_images/crop_meme_0_pt_83.jpg\tthese                    \t0.9471\n",
            "cropped_images/crop_meme_0_pt_84.jpg\tset                      \t0.9642\n",
            "cropped_images/crop_meme_0_pt_85.jpg\tbacks                    \t0.9969\n",
            "cropped_images/crop_meme_0_pt_86.jpg\tare                      \t0.8798\n",
            "cropped_images/crop_meme_0_pt_87.jpg\tall                      \t0.9960\n",
            "cropped_images/crop_meme_0_pt_88.jpg\tquite                    \t0.9811\n",
            "cropped_images/crop_meme_0_pt_89.jpg\tsover                    \t0.4480\n",
            "cropped_images/crop_meme_0_pt_90.jpg\ta                        \t0.3896\n",
            "cropped_images/crop_meme_0_pt_91.jpg\tmight                    \t0.9995\n",
            "cropped_images/crop_meme_0_pt_92.jpg\thave                     \t0.9424\n",
            "cropped_images/crop_meme_0_pt_93.jpg\tfixed                    \t0.9989\n",
            "cropped_images/crop_meme_0_pt_94.jpg\tthem                     \t0.9990\n",
            "cropped_images/crop_meme_0_pt_95.jpg\twith                     \t0.9999\n",
            "cropped_images/crop_meme_0_pt_96.jpg\thacks                    \t0.8109\n",
            "cropped_images/crop_meme_0_pt_97.jpg\there                     \t0.9809\n",
            "cropped_images/crop_meme_0_pt_98.jpg\tor                       \t0.9988\n",
            "cropped_images/crop_meme_0_pt_99.jpg\tthere                    \t0.9999\n",
            "cropped_images/crop_meme_0_pt_100.jpg\tBut                      \t0.9975\n",
            "cropped_images/crop_meme_0_pt_101.jpg\twhen                     \t0.9995\n",
            "cropped_images/crop_meme_0_pt_102.jpg\tfilters                  \t0.7260\n",
            "cropped_images/crop_meme_0_pt_103.jpg\ttook                     \t0.5199\n",
            "cropped_images/crop_meme_0_pt_104.jpg\tsparkle                  \t0.8447\n",
            "cropped_images/crop_meme_0_pt_105.jpg\tfrom                     \t0.9990\n",
            "cropped_images/crop_meme_0_pt_106.jpg\tyour                     \t0.9996\n",
            "cropped_images/crop_meme_0_pt_107.jpg\teyes                     \t0.2085\n",
            "cropped_images/crop_meme_0_pt_108.jpg\tI                        \t0.2047\n",
            "cropped_images/crop_meme_0_pt_109.jpg\tsaid,                    \t0.9947\n",
            "cropped_images/crop_meme_0_pt_110.jpg\tDamn                     \t0.9707\n",
            "cropped_images/crop_meme_0_pt_111.jpg\tall                      \t0.9972\n",
            "cropped_images/crop_meme_0_pt_112.jpg\tthis.                    \t0.9944\n",
            "cropped_images/crop_meme_0_pt_113.jpg\tI'll                     \t0.9924\n",
            "cropped_images/crop_meme_0_pt_114.jpg\tjust                     \t0.9993\n",
            "cropped_images/crop_meme_0_pt_115.jpg\tdigitize.                \t0.8738\n",
            "cropped_images/crop_meme_0_pt_116.jpg\tThomas                   \t0.9927\n",
            "cropped_images/crop_meme_0_pt_117.jpg\tColth                    \t0.7731\n",
            "cropped_images/crop_meme_0_pt_118.jpg\tnost                     \t0.4257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao6w8hlD_Yhy"
      },
      "source": [
        "word_cf_dict = {} # id: [word, confidence_score]\n",
        "sentence_dict = {}\n",
        "with open(\"./log_demo_result.txt\", 'r') as f: \n",
        "  reg = f.read()\n",
        "reg = list(reg.strip().split(\"\\n\"))\n",
        "words = []\n",
        "sentence = ''\n",
        "for text in reg[3:]:\n",
        "  text_id_old = text_id\n",
        "  text_list = text.split(\"\\t\")\n",
        "  file_name = text_list[0]\n",
        "  img_no = re.search('meme_(.+?)_', file_name)\n",
        "  if img_no:\n",
        "      text_id = int(img_no.group(1))\n",
        "  if text_id != text_id_old:\n",
        "    words = []\n",
        "    sentence = ''\n",
        "  # print(type(text_list[1]))\n",
        "  word = text_list[1]\n",
        "  cf = float(text_list[2])\n",
        "  if text:\n",
        "    word = word.strip()\n",
        "    words.append([word, cf])\n",
        "    sentence += word + ' '\n",
        "  word_cf_dict[text_id] = words \n",
        "  sentence_dict[text_id] = sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubkEgFfmnWcO",
        "outputId": "e38028a6-a39e-46b3-ce29-d71bf5cc64da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentence_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: \"Sonnet for Lena 0 dear Lenu, your beauly is so vast It is hard somet lines to describe it fast, I thought the entire world I would impress the only your portrait I could compross. Alas! First when I tried to use Vq I found that your checks belong to only you. Your silky hair contains a thousand lines Hard to match with sums of discrete cosines. And for your lips, sensual and tactual Thirteen Crays found not the proper fractal. And while these set backs are all quite sover a might have fixed them with hacks here or there But when filters took sparkle from your eyes I said, Damn all this. I'll just digitize. Thomas Colth nost \"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ52PWTM6dpx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}